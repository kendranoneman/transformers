{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4e17bc",
   "metadata": {},
   "source": [
    "# ML Final Report\n",
    "### Ben Richardson and Kendra Noneman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526edc3",
   "metadata": {},
   "source": [
    "#### Link for documentation: https://huggingface.co/docs/transformers/model_doc/clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a2fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ace0dd",
   "metadata": {},
   "source": [
    "### Acoustic Model:\n",
    "\n",
    "##### Hubert: \n",
    "\"Forces the model to learn a combined acoustic and language model over the continuous inputs\":\n",
    "https://huggingface.co/docs/transformers/v4.24.0/en/model_doc/hubert#overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a3139",
   "metadata": {},
   "source": [
    "### Multimodal Model:\n",
    "\n",
    "##### CLIPModel:\n",
    "Model configuration class with all the parameters of the model. Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
    " \n",
    "##### from_pretrained:\n",
    "Changes the weights (including mapping hidden states to vocabulary, pruning and initializing weights, tying the weights between the input embeddings and the output embeddings, etc...)\n",
    "https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\n",
    "\n",
    "Options for CLIP pre-trained openai models (4 of them):\n",
    "https://huggingface.co/openai\n",
    "\n",
    "##### CLIPProcessor:\n",
    "Constructs a CLIP processor which wraps a CLIP feature extractor and a CLIP tokenizer into a single processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad53763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4c3fa37d7b4e82a0bc9559481c1e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5f43ece8eb48208709c94037b77b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92785fe4992d4c4da28f83f79479d2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b0c4db0b4a4332b74e85048b66c831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686b7b5f89d443358156153044b3fb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b745fdaf51694b3f847a206905a6aca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cd91fa1e724699b2213c824ddddbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887f3bf170824abb9c19b61ef37d7f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95caea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a65692",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa75601",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa0187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
